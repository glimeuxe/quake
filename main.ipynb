{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import uuid\n",
    "from architectures import *\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import *\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 37\n",
    "ROOT_PATH = os.getcwd()\n",
    "os.makedirs(LOGS_PATH := os.path.join(ROOT_PATH, \"logs\"), exist_ok=True)\n",
    "os.makedirs(RAW_DATASET_PATH := os.path.join(ROOT_PATH, \"dataset\", \"raw\"), exist_ok=True)\n",
    "os.makedirs(PRODUCTION_DATASET_PATH := os.path.join(ROOT_PATH, \"dataset\", \"production\"), exist_ok=True)\n",
    "os.makedirs(MODELS_PATH := os.path.join(ROOT_PATH, \"models\"), exist_ok=True)\n",
    "\n",
    "SUBSAMPLE_SIZE = 10000\n",
    "NOISE_RATIO = 0.5\n",
    "EARTHQUAKE_RATIO = 0.5\n",
    "\n",
    "PROCESSING_METHOD = 2\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50\n",
    "PATIENCE = 7\n",
    "\n",
    "seed_functions(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "\t\"\"\"Computes, saves, and prints summary of preprocessed data.\"\"\"\n",
    "\t# Compute preprocessed data\n",
    "\tdata_processor = DataPreprocessing(\n",
    "\t\tsubsample_size=SUBSAMPLE_SIZE,\n",
    "\t\traw_dataset_path=RAW_DATASET_PATH,\n",
    "\t\tlogs_path=LOGS_PATH,\n",
    "\t\tnoise_ratio=NOISE_RATIO,\n",
    "\t\tearthquake_ratio=EARTHQUAKE_RATIO\n",
    "\t)\n",
    "\n",
    "\t# Save preprocessed data\n",
    "\tsignals = data_processor.subsample_traces\n",
    "\tnp.save(os.path.join(PRODUCTION_DATASET_PATH, f\"signals_{SUBSAMPLE_SIZE}.npy\"), np.array(list(signals.values())))\n",
    "\tmetadata = data_processor.subsample_metadata\n",
    "\tmetadata.to_feather(os.path.join(PRODUCTION_DATASET_PATH, f\"metadata_{SUBSAMPLE_SIZE}.feather\"))\n",
    "\twaveform_images = data_processor.create_waveform_images()\n",
    "\tnp.save(os.path.join(PRODUCTION_DATASET_PATH, f\"waveform_images_{SUBSAMPLE_SIZE}.npy\"), waveform_images)\n",
    "\tspectrogram_images = data_processor.create_spectrogram_images()\n",
    "\tnp.save(os.path.join(PRODUCTION_DATASET_PATH, f\"spectrogram_images_{SUBSAMPLE_SIZE}.npy\"), spectrogram_images)\n",
    "\n",
    "\t# Print summary of preprocessed data\n",
    "\tprint(f\"\"\"\n",
    "\t1. Expected samples: {SUBSAMPLE_SIZE}\n",
    "\t2. Actual samples: {len(signals)}\\n{metadata['category'].value_counts(normalize=True)}\n",
    "\t\"\"\")\n",
    "\n",
    "# preprocess_data()\n",
    "\n",
    "def visualise_data(num_samples=1):\n",
    "\t\"\"\"Randomly selects and plots pair(s) of annotated waveform and spectrogram images.\"\"\"\n",
    "\t# Load saved images\n",
    "\twaveform_images = np.load(os.path.join(PRODUCTION_DATASET_PATH, f\"waveform_images_{SUBSAMPLE_SIZE}.npy\"))\n",
    "\tspectrogram_images = np.load(os.path.join(PRODUCTION_DATASET_PATH, f\"spectrogram_images_{SUBSAMPLE_SIZE}.npy\"))\n",
    "\n",
    "\t# Create figure with subplots\n",
    "\tfig, axes = plt.subplots(num_samples, 2, figsize=(6, 3 * num_samples))\n",
    "\n",
    "\t# Ensure axes is iterable for a single sample case\n",
    "\tif num_samples == 1: axes = [axes]\n",
    "\n",
    "\t# Plot random images\n",
    "\tfor i1, i2 in enumerate(np.random.choice(len(waveform_images), num_samples, replace=False)):\n",
    "\t\taxes[i1][0].imshow(waveform_images[i2])\n",
    "\t\taxes[i1][0].set_title(f\"Waveform {i2}\")\n",
    "\t\taxes[i1][0].axis(\"off\")\n",
    "\t\taxes[i1][1].imshow(spectrogram_images[i2])\n",
    "\t\taxes[i1][1].set_title(f\"Spectrogram {i2}\")\n",
    "\t\taxes[i1][1].axis(\"off\")\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "visualise_data()\n",
    "\n",
    "def visualise_raw_data(num_samples=1):\n",
    "\t\"\"\"Randomly selects and plots a raw spectrogram image.\"\"\"\n",
    "\t# Load raw spectrogram model inputs\n",
    "\tspectrogram_images = np.load(os.path.join(PRODUCTION_DATASET_PATH, f\"spectrogram_images_{SUBSAMPLE_SIZE}.npy\"))\n",
    "\n",
    "\t# Select random samples\n",
    "\tindices = np.random.choice(len(spectrogram_images), num_samples, replace=False)\n",
    "\n",
    "\t# Plot images\n",
    "\tfig, axes = plt.subplots(1, num_samples, figsize=(num_samples * 3, 3))\n",
    "\tif num_samples == 1:\n",
    "\t\taxes = [axes]\n",
    "\n",
    "\tfor ax, idx in zip(axes, indices):\n",
    "\t\timg = spectrogram_images[idx]\n",
    "\t\tax.imshow(img)\n",
    "\t\tax.axis(\"off\")\n",
    "\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "# visualise_raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SCNNQ730().to(DEVICE) if PROCESSING_METHOD == 1 else BiLSTMF().to(DEVICE)\n",
    "print(model)\n",
    "\n",
    "# Compute labels\n",
    "metadata = pd.read_feather(os.path.join(PRODUCTION_DATASET_PATH, f\"metadata_{SUBSAMPLE_SIZE}.feather\"))\n",
    "labels = (metadata[\"category\"] == \"earthquake\").astype(np.float32).values  # 0 (noise), 1 (earthquake)\n",
    "labels = torch.tensor(labels).view(-1, 1)\n",
    "\n",
    "def split_data(data, labels, test_size=0.2, dev_size=0.5):\n",
    "\ttrain_i, temp_i, train_labels, temp_labels = train_test_split(\n",
    "\t\tdata, labels, test_size=test_size, stratify=labels, random_state=SEED\n",
    "\t)\n",
    "\tdev_i, test_i, dev_labels, test_labels = train_test_split(\n",
    "\t\ttemp_i, temp_labels, test_size=dev_size, stratify=temp_labels, random_state=SEED\n",
    "\t)\n",
    "\treturn train_i, train_labels, dev_i, dev_labels, test_i, test_labels\n",
    "\n",
    "if PROCESSING_METHOD == 1:\n",
    "\tspectrograms = np.load(os.path.join(PRODUCTION_DATASET_PATH, f\"spectrogram_images_{SUBSAMPLE_SIZE}.npy\"))\n",
    "\tspectrograms = torch.tensor(spectrograms.astype(np.float32) / 255.0).permute(0, 3, 1, 2)\n",
    "\ttrain_i, train_labels, dev_i, dev_labels, test_i, test_labels = split_data(spectrograms, labels)\n",
    "\n",
    "\tdef load_data(model):\n",
    "\t\ttrain_generator = torch.Generator()\n",
    "\t\ttrain_generator.manual_seed(SEED)\n",
    "\n",
    "\t\tif getattr(model, \"expects224\", False):\n",
    "\t\t\ttrain_loader = DataLoader(SpectrogramDataset224(SpectrogramDataset(train_i, train_labels)), batch_size=BATCH_SIZE, shuffle=True, generator=train_generator)\n",
    "\t\t\tdev_loader = DataLoader(SpectrogramDataset224(SpectrogramDataset(dev_i, dev_labels)), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\t\t\ttest_loader = DataLoader(SpectrogramDataset224(SpectrogramDataset(test_i, test_labels)), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\t\t\treturn train_loader, dev_loader, test_loader\n",
    "\n",
    "\t\ttrain_loader = DataLoader(SpectrogramDataset(train_i, train_labels), batch_size=BATCH_SIZE, shuffle=True, generator=train_generator)\n",
    "\t\tdev_loader = DataLoader(SpectrogramDataset(dev_i, dev_labels), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\t\ttest_loader = DataLoader(SpectrogramDataset(test_i, test_labels), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\t\treturn train_loader, dev_loader, test_loader\n",
    "\n",
    "\ttrain_loader, dev_loader, test_loader = load_data(model)\n",
    "else:\n",
    "\tsignals = np.load(os.path.join(PRODUCTION_DATASET_PATH, f\"signals_{SUBSAMPLE_SIZE}.npy\"))\n",
    "\tsignal_envelopes = np.array([hilbert_transform_rolling_avg(raw_signal, resampled=True) for raw_signal in signals])\n",
    "\tsignal_envelopes = torch.tensor(signal_envelopes.astype(np.float32)).unsqueeze(-1)\n",
    "\ttrain_i, train_labels, dev_i, dev_labels, test_i, test_labels = split_data(signal_envelopes, labels)\n",
    "\n",
    "\tdef load_data():\n",
    "\t\ttrain_generator = torch.Generator()\n",
    "\t\ttrain_generator.manual_seed(SEED)\n",
    "\n",
    "\t\ttrain_loader = DataLoader(SpectrogramDataset(train_i, train_labels), batch_size=BATCH_SIZE, shuffle=True, generator=train_generator)\n",
    "\t\tdev_loader = DataLoader(SpectrogramDataset(dev_i, dev_labels), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\t\ttest_loader = DataLoader(SpectrogramDataset(test_i, test_labels), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\t\treturn train_loader, dev_loader, test_loader\n",
    "\n",
    "\ttrain_loader, dev_loader, test_loader = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE TO PROCESS DATA USING METHOD 1 ONLY\n",
    "model = ViTB16().to(DEVICE)\n",
    "\n",
    "# Load production dataset and compute labels\n",
    "spectrograms = np.load(os.path.join(PRODUCTION_DATASET_PATH, f\"spectrogram_images_{SUBSAMPLE_SIZE}.npy\"))\n",
    "metadata = pd.read_feather(os.path.join(PRODUCTION_DATASET_PATH, f\"metadata_{SUBSAMPLE_SIZE}.feather\"))\n",
    "labels = (metadata[\"category\"] == \"earthquake\").astype(np.float32).values  # 0 (noise), 1 (earthquake)\n",
    "\n",
    "# Normalize and convert spectrograms and labels to tensors\n",
    "spectrograms = torch.tensor(spectrograms.astype(np.float32) / 255.0).permute(0, 3, 1, 2)\n",
    "labels = torch.tensor(labels).view(-1, 1)\n",
    "\n",
    "def split_data(spectrograms, labels, test_size=0.2, dev_size=0.5):\n",
    "\ttrain_i, temp_i, train_labels, temp_labels = train_test_split(spectrograms, labels, test_size=test_size, stratify=labels, random_state=SEED)\n",
    "\tdev_i, test_i, dev_labels, test_labels = train_test_split(temp_i, temp_labels, test_size=dev_size, stratify=temp_labels, random_state=SEED)\n",
    "\treturn train_i, train_labels, dev_i, dev_labels, test_i, test_labels\n",
    "\n",
    "# Split production dataset into train, dev, and test sets\n",
    "train_i, train_labels, dev_i, dev_labels, test_i, test_labels = split_data(spectrograms, labels)\n",
    "\n",
    "def load_data(model):\n",
    "\ttrain_generator = torch.Generator()\n",
    "\ttrain_generator.manual_seed(SEED)\n",
    "\n",
    "\tif getattr(model, \"expects224\", False):\n",
    "\t\ttrain_loader = DataLoader(SpectrogramDataset224(SpectrogramDataset(train_i, train_labels)), batch_size=BATCH_SIZE, shuffle=True, generator=train_generator)\n",
    "\t\tdev_loader = DataLoader(SpectrogramDataset224(SpectrogramDataset(dev_i, dev_labels)), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\t\ttest_loader = DataLoader(SpectrogramDataset224(SpectrogramDataset(test_i, test_labels)), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\t\treturn train_loader, dev_loader, test_loader\n",
    "\n",
    "\ttrain_loader = DataLoader(SpectrogramDataset(train_i, train_labels), batch_size=BATCH_SIZE, shuffle=True, generator=train_generator)\n",
    "\tdev_loader = DataLoader(SpectrogramDataset(dev_i, dev_labels), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\ttest_loader = DataLoader(SpectrogramDataset(test_i, test_labels), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\treturn train_loader, dev_loader, test_loader\n",
    "\n",
    "train_loader, dev_loader, test_loader = load_data(model)\n",
    "\n",
    "# CODE TO PROCESS DATA USING METHOD 2 ONLY\n",
    "model = BiLSTMF().to(DEVICE)\n",
    "\n",
    "# Load production dataset and compute labels\n",
    "signals = np.load(os.path.join(PRODUCTION_DATASET_PATH, f\"signals_{SUBSAMPLE_SIZE}.npy\"))\n",
    "metadata = pd.read_feather(os.path.join(PRODUCTION_DATASET_PATH, f\"metadata_{SUBSAMPLE_SIZE}.feather\"))\n",
    "labels = (metadata[\"category\"] == \"earthquake\").astype(np.float32).values  # 0 (noise), 1 (earthquake)\n",
    "\n",
    "# Convert signals into envelopes\n",
    "signal_envelopes = np.array([hilbert_transform_rolling_avg(raw_signal, resampled=True) for raw_signal in signals])\n",
    "\n",
    "# Convert envelopes and labels to tensors\n",
    "signal_envelopes = torch.tensor(signal_envelopes.astype(np.float32)).unsqueeze(-1)\n",
    "labels = torch.tensor(labels).view(-1, 1)\n",
    "\n",
    "def split_data(signal_envelopes, labels, test_size=0.2, dev_size=0.5):\n",
    "\ttrain_i, temp_i, train_labels, temp_labels = train_test_split(signal_envelopes, labels, test_size=test_size, stratify=labels, random_state=SEED)\n",
    "\tdev_i, test_i, dev_labels, test_labels = train_test_split(temp_i, temp_labels, test_size=dev_size, stratify=temp_labels, random_state=SEED)\n",
    "\treturn train_i, train_labels, dev_i, dev_labels, test_i, test_labels\n",
    "\n",
    "# Split production dataset into train, dev, and test sets\n",
    "train_i, train_labels, dev_i, dev_labels, test_i, test_labels = split_data(signal_envelopes, labels)\n",
    "\n",
    "def load_data():\n",
    "\ttrain_generator = torch.Generator()\n",
    "\ttrain_generator.manual_seed(SEED)\n",
    "\n",
    "\ttrain_loader = DataLoader(SpectrogramDataset(train_i, train_labels), batch_size=BATCH_SIZE, shuffle=True, generator=train_generator)\n",
    "\tdev_loader = DataLoader(SpectrogramDataset(dev_i, dev_labels), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\ttest_loader = DataLoader(SpectrogramDataset(test_i, test_labels), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\treturn train_loader, dev_loader, test_loader\n",
    "\n",
    "train_loader, dev_loader, test_loader = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, dev_loader, criterion, optimizer):\n",
    "\t# Create model folder\n",
    "\tmodel_folder = os.path.join(MODELS_PATH, f\"{model.id}\")\n",
    "\tos.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "\tbest_dev_loss = float(\"inf\")\n",
    "\tbest_model_path = os.path.join(model_folder, \"best.pth\")\n",
    "\tpatience_counter = 0\n",
    "\ttrain_losses = []\n",
    "\tdev_losses = []\n",
    "\n",
    "\tfor epoch in range(NUM_EPOCHS):\n",
    "\t\t# Train model on train set\n",
    "\t\tmodel.train()\n",
    "\t\ttotal_loss = 0\n",
    "\t\tfor images, labels in train_loader:\n",
    "\t\t\timages, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\ttotal_loss += loss.item()\n",
    "\t\ttrain_loss = total_loss / len(train_loader)\n",
    "\t\ttrain_losses.append(train_loss)\n",
    "\n",
    "\t\t# Evaluate model on dev set\n",
    "\t\tmodel.eval()\n",
    "\t\tdev_loss = 0\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor images, labels in dev_loader:\n",
    "\t\t\t\timages, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\t\t\t\toutputs = model(images)\n",
    "\t\t\t\tdev_loss += criterion(outputs, labels).item()\n",
    "\t\tdev_loss /= len(dev_loader)\n",
    "\t\tdev_losses.append(dev_loss)\n",
    "\n",
    "\t\tprint(f\"Epoch: {epoch+1} of {NUM_EPOCHS} - Training loss: {train_loss:.4f} - Validation loss: {dev_loss:.4f}\")\n",
    "\n",
    "\t\t# Save model epoch checkpoint\n",
    "\t\ttorch.save(model.state_dict(), os.path.join(model_folder, f\"epoch={epoch+1}-dev_loss={dev_loss:.4f}.pth\"))\n",
    "\t\tif dev_loss < best_dev_loss:\n",
    "\t\t\tbest_dev_loss = dev_loss\n",
    "\t\t\ttorch.save(model.state_dict(), best_model_path)  # Save best model\n",
    "\t\t\tpatience_counter = 0  # Reset patience counter\n",
    "\t\telse:\n",
    "\t\t\tpatience_counter += 1\n",
    "\t\t\t# Stop early if needed\n",
    "\t\t\tif patience_counter >= PATIENCE:\n",
    "\t\t\t\tprint(\"Stopping early\")\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t# Save losses\n",
    "\tloss_data = {\"train_losses\": train_losses, \"dev_losses\": dev_losses}\n",
    "\twith open(os.path.join(model_folder, \"losses.json\"), \"w\") as f:\n",
    "\t\tjson.dump(loss_data, f)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "train_model(model, train_loader, dev_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_loss(model):\n",
    "\t# Load losses\n",
    "\tmodel_folder = os.path.join(MODELS_PATH, f\"{model.id}\")\n",
    "\twith open(os.path.join(model_folder, \"losses.json\"), \"r\") as f:\n",
    "\t\tloss_data = json.load(f)\n",
    "\ttrain_losses = loss_data[\"train_losses\"]\n",
    "\tdev_losses = loss_data[\"dev_losses\"]\n",
    "\n",
    "\tplt.figure(figsize=(8, 5))\n",
    "\tepochs = range(1, len(train_losses) + 1)\n",
    "\tplt.plot(epochs, train_losses, \"b-\", label=\"Training loss\")\n",
    "\tplt.plot(epochs, dev_losses, \"r-\", label=\"Validation loss\")\n",
    "\n",
    "\t# Annotate the best loss\n",
    "\tbest_epoch = np.argmin(dev_losses) + 1\n",
    "\tbest_loss = min(dev_losses)\n",
    "\tplt.plot(best_epoch, best_loss, \"ro\", markersize=8, label=f\"Best loss: {best_loss:.4f}\")\n",
    "\n",
    "\tplt.xlabel(\"Epoch\")\n",
    "\tplt.ylabel(\"Loss\")\n",
    "\tplt.legend()\n",
    "\tplt.gca().xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "# M = [SR50ViTB16(), R50ViTB16(), R26ViTS32(), SCNNQ730(), CNNQ730(), BiLSTMF(), LSTMH(), ViTB32(), ViTB16()]\n",
    "# multivisualise_training_loss(M)\n",
    "# multivisualise_validation_loss(M)\n",
    "\n",
    "# m = model.__class__().to(DEVICE)\n",
    "# visualise_loss(m)\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "\tmodel.eval()\n",
    "\tY_hat, Y = [], []\n",
    "\twith torch.no_grad():\n",
    "\t\tfor x, y in dataloader:\n",
    "\t\t\tY_hat.append(model(x.to(DEVICE)).round().cpu())\n",
    "\t\t\tY.append(y)\n",
    "\ttn, fp, fn, tp = confusion_matrix(torch.cat(Y), torch.cat(Y_hat)).ravel()\n",
    "\tf1 = compute_macro_f1(tp, tn, fp, fn)\n",
    "\treturn {\n",
    "\t\t\"tp\": int(tp),\n",
    "\t\t\"tn\": int(tn),\n",
    "\t\t\"fp\": int(fp),\n",
    "\t\t\"fn\": int(fn),\n",
    "\t\t\"f1\": float(f1)\n",
    "\t}\n",
    "\n",
    "def load_weights(model):\n",
    "\tstate_dict = torch.load(os.path.join(MODELS_PATH, model.id, \"best.pth\"), weights_only=False)\n",
    "\tstate_dict.pop(\"_metadata\", None)\n",
    "\tmodel.load_state_dict(state_dict)\n",
    "\n",
    "m = model.__class__().to(DEVICE)\n",
    "load_weights(m)\n",
    "print(evaluate_model(m, test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
