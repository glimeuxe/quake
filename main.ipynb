{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 1: train_loss = 0.44284, val_loss = 0.29276\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 2: train_loss = 0.35069, val_loss = 0.28900\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 3: train_loss = 0.34937, val_loss = 0.29180\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 4: train_loss = 0.34863, val_loss = 0.28913\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 5: train_loss = 0.34843, val_loss = 0.28936\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 6: train_loss = 0.34722, val_loss = 0.28758\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 7: train_loss = 0.34710, val_loss = 0.29278\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 8: train_loss = 0.34709, val_loss = 0.28792\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 9: train_loss = 0.34578, val_loss = 0.28912\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 10: train_loss = 0.34544, val_loss = 0.28986\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 11: train_loss = 0.34675, val_loss = 0.28928\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 12: train_loss = 0.34525, val_loss = 0.28816\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 13: train_loss = 0.34435, val_loss = 0.29025\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 14: train_loss = 0.34691, val_loss = 0.28816\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 15: train_loss = 0.34377, val_loss = 0.28928\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 16: train_loss = 0.34398, val_loss = 0.29084\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 17: train_loss = 0.34477, val_loss = 0.28903\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 18: train_loss = 0.34341, val_loss = 0.28792\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 19: train_loss = 0.34412, val_loss = 0.28809\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 20: train_loss = 0.34403, val_loss = 0.29025\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 21: train_loss = 0.34493, val_loss = 0.29045\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 22: train_loss = 0.34493, val_loss = 0.29199\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 23: train_loss = 0.34468, val_loss = 0.29012\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 24: train_loss = 0.34358, val_loss = 0.28910\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 25: train_loss = 0.34350, val_loss = 0.28811\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 26: train_loss = 0.34273, val_loss = 0.28922\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 27: train_loss = 0.34307, val_loss = 0.28972\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 28: train_loss = 0.34258, val_loss = 0.28973\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 29: train_loss = 0.34282, val_loss = 0.28919\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 30: train_loss = 0.34285, val_loss = 0.28872\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 31: train_loss = 0.34251, val_loss = 0.28915\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 32: train_loss = 0.34319, val_loss = 0.28977\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 33: train_loss = 0.34302, val_loss = 0.29076\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 34: train_loss = 0.34243, val_loss = 0.29026\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 35: train_loss = 0.34295, val_loss = 0.28883\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 36: train_loss = 0.34269, val_loss = 0.29038\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 37: train_loss = 0.34264, val_loss = 0.28928\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 38: train_loss = 0.34197, val_loss = 0.28974\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 39: train_loss = 0.34255, val_loss = 0.29037\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 40: train_loss = 0.34226, val_loss = 0.29033\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 41: train_loss = 0.34112, val_loss = 0.29026\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 42: train_loss = 0.34111, val_loss = 0.29264\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 43: train_loss = 0.34178, val_loss = 0.28812\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 44: train_loss = 0.34142, val_loss = 0.29004\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 45: train_loss = 0.34145, val_loss = 0.29147\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 46: train_loss = 0.34157, val_loss = 0.28948\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 47: train_loss = 0.34177, val_loss = 0.29006\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 48: train_loss = 0.34155, val_loss = 0.29200\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 49: train_loss = 0.34117, val_loss = 0.28963\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 50: train_loss = 0.34036, val_loss = 0.29370\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 51: train_loss = 0.34079, val_loss = 0.28771\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 52: train_loss = 0.34016, val_loss = 0.29150\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 53: train_loss = 0.34063, val_loss = 0.28875\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 54: train_loss = 0.34015, val_loss = 0.28933\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 55: train_loss = 0.34022, val_loss = 0.29172\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 56: train_loss = 0.33932, val_loss = 0.28903\n",
      "Stopping early\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 1: train_loss = 0.32997, val_loss = 0.31202\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 2: train_loss = 0.32938, val_loss = 0.30992\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 3: train_loss = 0.32856, val_loss = 0.30561\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 4: train_loss = 0.32786, val_loss = 0.30353\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 5: train_loss = 0.32713, val_loss = 0.30873\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 6: train_loss = 0.32783, val_loss = 0.30847\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 7: train_loss = 0.32778, val_loss = 0.30519\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 8: train_loss = 0.32742, val_loss = 0.30877\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 9: train_loss = 0.32709, val_loss = 0.30686\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 10: train_loss = 0.32752, val_loss = 0.30547\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 11: train_loss = 0.32673, val_loss = 0.30434\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 12: train_loss = 0.32681, val_loss = 0.30636\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 13: train_loss = 0.32673, val_loss = 0.30436\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 14: train_loss = 0.32736, val_loss = 0.30317\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 15: train_loss = 0.32665, val_loss = 0.30516\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 16: train_loss = 0.32642, val_loss = 0.30444\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 17: train_loss = 0.32681, val_loss = 0.30499\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 18: train_loss = 0.32677, val_loss = 0.30616\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 19: train_loss = 0.32664, val_loss = 0.30393\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 20: train_loss = 0.32569, val_loss = 0.30737\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 21: train_loss = 0.32595, val_loss = 0.30523\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 22: train_loss = 0.32584, val_loss = 0.30461\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 23: train_loss = 0.32629, val_loss = 0.30452\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 24: train_loss = 0.32565, val_loss = 0.30628\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 25: train_loss = 0.32562, val_loss = 0.30457\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 26: train_loss = 0.32484, val_loss = 0.30766\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 27: train_loss = 0.32530, val_loss = 0.30647\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 28: train_loss = 0.32622, val_loss = 0.30883\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 29: train_loss = 0.32510, val_loss = 0.30686\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 30: train_loss = 0.32523, val_loss = 0.31235\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 31: train_loss = 0.32689, val_loss = 0.30813\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 32: train_loss = 0.32682, val_loss = 0.31037\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 33: train_loss = 0.32438, val_loss = 0.31049\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 34: train_loss = 0.32477, val_loss = 0.31167\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 35: train_loss = 0.32405, val_loss = 0.31209\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 36: train_loss = 0.32464, val_loss = 0.31351\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 37: train_loss = 0.32336, val_loss = 0.31176\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 38: train_loss = 0.32327, val_loss = 0.31125\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 39: train_loss = 0.32268, val_loss = 0.31111\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 40: train_loss = 0.32381, val_loss = 0.31247\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 41: train_loss = 0.32294, val_loss = 0.32360\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 42: train_loss = 0.32373, val_loss = 0.32942\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 43: train_loss = 0.32374, val_loss = 0.31343\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 44: train_loss = 0.32264, val_loss = 0.31621\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 45: train_loss = 0.32226, val_loss = 0.31524\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 46: train_loss = 0.32349, val_loss = 0.31546\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 47: train_loss = 0.32174, val_loss = 0.31257\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 48: train_loss = 0.32113, val_loss = 0.31704\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 49: train_loss = 0.32284, val_loss = 0.31428\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 50: train_loss = 0.32146, val_loss = 0.31882\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 51: train_loss = 0.32112, val_loss = 0.32355\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 52: train_loss = 0.32146, val_loss = 0.31530\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 53: train_loss = 0.32091, val_loss = 0.31896\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 54: train_loss = 0.32092, val_loss = 0.31637\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 55: train_loss = 0.32094, val_loss = 0.31628\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 56: train_loss = 0.32094, val_loss = 0.33094\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 57: train_loss = 0.32064, val_loss = 0.31605\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 58: train_loss = 0.32051, val_loss = 0.32592\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 59: train_loss = 0.31947, val_loss = 0.32660\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 60: train_loss = 0.32009, val_loss = 0.32198\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 61: train_loss = 0.31948, val_loss = 0.31857\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 62: train_loss = 0.31960, val_loss = 0.33374\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 63: train_loss = 0.31999, val_loss = 0.32004\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0 epoch 64: train_loss = 0.31991, val_loss = 0.32269\n",
      "Stopping early\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0: 0.053636044\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0: 0.003371380\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0: 0.004680249\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0: 0.054707333\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0: 0.003416558\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0: 0.006430539\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0: 0.054558404\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0: 0.003406061\n",
      "RNNLSTM(5-64-4-0.0)-0.001-0.0: 0.006075662\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import itertools\n",
    "import joblib\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "BASE_PATH = os.path.expanduser(\"~/Code/ModelQuake\")\n",
    "DATA_PATH = os.path.join(BASE_PATH, \"data\")\n",
    "if not os.path.exists(DATA_PATH): os.makedirs(DATA_PATH)\n",
    "DATA_FILE = os.path.join(BASE_PATH, \"data/database.csv\")\n",
    "if not os.path.isfile(DATA_FILE): raise Exception()\n",
    "SAVES_PATH = os.path.join(BASE_PATH, \"saves\")\n",
    "if not os.path.exists(SAVES_PATH): os.makedirs(SAVES_PATH)\n",
    "METRICS_FILE = os.path.join(BASE_PATH, \"saves/all.metrics\")\n",
    "if not os.path.isfile(METRICS_FILE):\n",
    "\twith open(METRICS_FILE, \"w\") as f:\n",
    "\t\tf.write(\"[]\")\n",
    "\n",
    "WINDOW_RADIUS = 15\n",
    "WINDOW_INTERVAL = 30 * 24 * 60 * 60\n",
    "\n",
    "# PROCESSING PHASE\n",
    "class Dataset(Dataset):\n",
    "\tdef __init__(self, X, y):\n",
    "\t\tself.X = torch.tensor(X, dtype=torch.float32)\n",
    "\t\tself.y = torch.tensor(y, dtype=torch.float32)\n",
    "\tdef __getitem__(self, i): return self.X[i], self.y[i]\n",
    "\tdef __len__(self): return len(self.X)\n",
    "\n",
    "def process_data():\n",
    "\tdf = pd.read_csv(DATA_FILE)\n",
    "\tdf[\"timestamp\"] = pd.to_datetime(df[\"Date\"] + \" \" + df[\"Time\"], errors=\"coerce\")\n",
    "\tdf = df.dropna(subset=[\"timestamp\", \"Latitude\", \"Longitude\", \"Depth\", \"Magnitude\"])\n",
    "\tdf[\"timestamp\"] = df[\"timestamp\"].astype(np.int64) // 10**9\n",
    "\n",
    "\tX = df[[\"timestamp\", \"Latitude\", \"Longitude\", \"Depth\", \"Magnitude\"]].values\n",
    "\ty = np.zeros(len(df), dtype=np.float32)\n",
    "\n",
    "\ttree = cKDTree(df[[\"Latitude\", \"Longitude\"]])\n",
    "\ttimestamps = df[\"timestamp\"].values\n",
    "\tfor i, (lat, lon, ts) in enumerate(zip(df[\"Latitude\"], df[\"Longitude\"], timestamps)):\n",
    "\t\tindices = tree.query_ball_point([lat, lon], WINDOW_RADIUS / 6371 * (180 / np.pi))\n",
    "\t\tfor j in indices:\n",
    "\t\t\tif i != j and ts < timestamps[j] < ts + WINDOW_INTERVAL:\n",
    "\t\t\t\ty[i] = 1\n",
    "\t\t\t\tbreak\n",
    "\treturn X, y\n",
    "\n",
    "X, y = process_data()\n",
    "\n",
    "# SELECTION PHASE\n",
    "class BaseModel(nn.Module):\n",
    "\tdef __init__(self, id):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.id = id\n",
    "\tdef forward(self, x): raise NotImplementedError()\n",
    "\n",
    "class RNNLSTMModel(BaseModel):\n",
    "\tdef __init__(self, input_dim, lstm_hidden_dim, num_layers, dropout, lr, weight_decay):\n",
    "\t\tsuper().__init__(f\"RNNLSTM({input_dim}-{lstm_hidden_dim}-{num_layers}-{dropout})-{lr}-{weight_decay}\")\n",
    "\t\tself.lstm = nn.LSTM(input_dim, lstm_hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "\t\tself.fc = nn.Linear(lstm_hidden_dim, 1)\n",
    "\tdef forward(self, x):\n",
    "\t\tx = x.unsqueeze(1)\n",
    "\t\t_, (h_n, _) = self.lstm(x)\n",
    "\t\toutput = self.fc(h_n[-1])\n",
    "\t\treturn torch.sigmoid(output).squeeze(-1)\n",
    "\n",
    "class MLPModel(BaseModel):\n",
    "\tdef __init__(self, input_dim, hidden_dim, num_layers, dropout, lr, weight_decay):\n",
    "\t\tsuper().__init__(f\"MLP({input_dim}-{hidden_dim}-{num_layers}-{dropout})-{lr}-{weight_decay}\")\n",
    "\n",
    "\t\tlayers = []\n",
    "\t\tfor _ in range(num_layers):\n",
    "\t\t\tlayers.append(nn.Linear(input_dim if len(layers) == 0 else hidden_dim, hidden_dim))\n",
    "\t\t\tlayers.append(nn.ReLU())\n",
    "\t\t\tlayers.append(nn.Dropout(dropout))\n",
    "\t\tlayers.append(nn.Linear(hidden_dim, 1))\n",
    "\n",
    "\t\tself.network = nn.Sequential(*layers)\n",
    "\tdef forward(self, x):\n",
    "\t\toutput = self.network(x)\n",
    "\t\treturn torch.sigmoid(output).squeeze(-1)\n",
    "\n",
    "def instantiate(model_type, **kwargs):\n",
    "\tif model_type == \"RNNLSTM\": return RNNLSTMModel(**kwargs)\n",
    "\telif model_type == \"MLP\": return MLPModel(**kwargs)\n",
    "\telse: raise ValueError(f\"Unknown model type {model_type}\")\n",
    "\n",
    "def save(model, epoch, train_loss, val_loss):\n",
    "\tmodel_folder = os.path.join(SAVES_PATH, model.id)\n",
    "\tos.makedirs(model_folder, exist_ok=True)\n",
    "\ttorch.save(model.state_dict(), os.path.join(model_folder, f\"epoch{epoch}.pth\"))\n",
    "\twith open(os.path.join(model_folder, f\"epoch{epoch}.losses\"), \"w\") as f:\n",
    "\t\tjson.dump({\"train\": train_loss, \"val\": val_loss}, f)\n",
    "\n",
    "def load(model, epoch=None):\n",
    "\tmodel_folder = os.path.join(SAVES_PATH, model.id)\n",
    "\tmodel_files = sorted(glob.glob(os.path.join(model_folder, \"*.pth\")), key=os.path.getmtime)\n",
    "\tif not model_files: return\n",
    "\tmodel_checkpoint = model_files[-1] if epoch is None else os.path.join(model_folder, f\"epoch{epoch}.pth\")\n",
    "\tmodel.load_state_dict(torch.load(model_checkpoint, map_location=DEVICE))\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "\tbest_val_loss = float(\"inf\")\n",
    "\tpatience_counter = 0\n",
    "\n",
    "\tfor epoch in range(1, epochs + 1):\n",
    "\t\tmodel.train()\n",
    "\t\ttrain_loss = 0\n",
    "\t\tfor X, y in train_loader:\n",
    "\t\t\tX = X.to(DEVICE)\n",
    "\t\t\ty = y.to(DEVICE)\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutput = model(X)\n",
    "\t\t\tloss = criterion(output, y)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\ttrain_loss += loss.item()\n",
    "\t\ttrain_loss /= len(train_loader)\n",
    "\n",
    "\t\tmodel.eval()\n",
    "\t\tval_loss = sum(criterion(model(X.to(DEVICE)), y.to(DEVICE)).item() for X, y in val_loader) / len(val_loader)\n",
    "\t\tprint(f\"{model.id} epoch {epoch}: train_loss = {train_loss:.5f}, val_loss = {val_loss:.5f}\")\n",
    "\t\tsave(model, epoch, train_loss, val_loss)\n",
    "\t\tif val_loss < best_val_loss:\n",
    "\t\t\tbest_val_loss = val_loss\n",
    "\t\t\tpatience_counter = 0\n",
    "\t\telse:\n",
    "\t\t\tpatience_counter += 1\n",
    "\t\t\tif patience_counter >= 50:\n",
    "\t\t\t\tprint(\"Stopping early\")\n",
    "\t\t\t\tbreak\n",
    "\n",
    "def evaluate(model, X_test, y_test):\n",
    "\tload(model)\n",
    "\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tprobabilities = model(torch.tensor(X_test, dtype=torch.float32).to(DEVICE)).squeeze().cpu().numpy()\n",
    "\tM = 0.5\n",
    "\tif not len(np.unique(y_test)) < 2: M = roc_auc_score(y_test, probabilities)\n",
    "\treturn round(M, 8)\n",
    "\n",
    "def crossvalidate(model, criterion, optimizer, X, y, id, folds, epochs):\n",
    "\tif folds == 1:\n",
    "\t\tπ = int(0.8 * len(X))\n",
    "\t\tX_train, y_train = X[:π], y[:π]\n",
    "\t\tX_test, y_test = X[π:], y[π:]\n",
    "\n",
    "\t\tscaler = StandardScaler()\n",
    "\t\tX_train = scaler.fit_transform(X_train)\n",
    "\t\tX_test = scaler.transform(X_test)\n",
    "\n",
    "\t\tjoblib.dump(scaler, os.path.join(SAVES_PATH, f\"{id}/scaler.pkl\"))\n",
    "\n",
    "\t\tυ = int(0.2 * len(X_train))\n",
    "\t\ttrain_loader = DataLoader(Dataset(X_train[υ:], y_train[υ:]), batch_size=64, shuffle=True)\n",
    "\t\tval_loader = DataLoader(Dataset(X_train[:υ], y_train[:υ]), batch_size=64)\n",
    "\n",
    "\t\ttrain(model, train_loader, val_loader, criterion, optimizer, epochs=epochs)\n",
    "\t\tM_list = [evaluate(model, X_test, y_test)]\n",
    "\telse:\n",
    "\t\tkf = KFold(n_splits=folds, shuffle=True, random_state=37)\n",
    "\t\tM_list = []\n",
    "\t\tbest_scaler = None\n",
    "\t\tbest_M = -float(\"inf\")\n",
    "\n",
    "\t\tfor train_i, test_i in kf.split(X):\n",
    "\t\t\tscaler = StandardScaler()\n",
    "\t\t\tX_train = scaler.fit_transform(X[train_i])\n",
    "\t\t\tX_test = scaler.transform(X[test_i])\n",
    "\t\t\ty_train = y[train_i]\n",
    "\t\t\ty_test = y[test_i]\n",
    "\n",
    "\t\t\tυ = int(0.2 * len(X_train))\n",
    "\t\t\ttrain_loader = DataLoader(Dataset(X_train[υ:], y_train[υ:]), batch_size=64, shuffle=True)\n",
    "\t\t\tval_loader = DataLoader(Dataset(X_train[:υ], y_train[:υ]), batch_size=64)\n",
    "\n",
    "\t\t\ttrain(model, train_loader, val_loader, criterion, optimizer, epochs=epochs)\n",
    "\t\t\tM = evaluate(model, X_test, y_test)\n",
    "\t\t\tif M > best_M:\n",
    "\t\t\t\tbest_M = M\n",
    "\t\t\t\tbest_scaler = scaler\n",
    "\t\t\tM_list.append(M)\n",
    "\n",
    "\tif best_scaler: joblib.dump(best_scaler, os.path.join(SAVES_PATH, f\"{id}/scaler.pkl\"))\n",
    "\n",
    "\trounded_mean_M = round(np.mean(M_list), 8)\n",
    "\tjson.dump(\n",
    "\t\t(json.load(open(METRICS_FILE)) if os.path.getsize(METRICS_FILE) > 0 else []) + [{\"id\": id, \"M\": rounded_mean_M}],\n",
    "\t\topen(METRICS_FILE, \"w\"),\n",
    "\t\tindent=2\n",
    "\t)\n",
    "\n",
    "def gridsearch(model_type, grid, X, y, folds=1, epochs=5):\n",
    "\tmetrics_dict = {}\n",
    "\tif os.path.getsize(METRICS_FILE) > 0:\n",
    "\t\twith open(METRICS_FILE) as f:\n",
    "\t\t\tmetrics_dict = {metrics_entry[\"id\"]: metrics_entry[\"M\"] for metrics_entry in json.load(f)}\n",
    "\n",
    "\tfor column in itertools.product(*grid.values()):\n",
    "\t\tkwargs = dict(zip(grid.keys(), column))\n",
    "\t\tmodel = instantiate(model_type, **kwargs).to(DEVICE)\n",
    "\t\tif model.id in metrics_dict: continue\n",
    "\t\tcriterion = nn.BCELoss()\n",
    "\t\toptimizer = optim.Adam(model.parameters(), lr=kwargs[\"lr\"], weight_decay=kwargs[\"weight_decay\"])\n",
    "\t\tcrossvalidate(model, criterion, optimizer, X, y, model.id, folds=folds, epochs=epochs)\n",
    "\n",
    "grid = {\n",
    "\t\"input_dim\": [5],\n",
    "\t\"lstm_hidden_dim\": [64],\n",
    "\t\"num_layers\": [4],\n",
    "\t\"dropout\": [0.0],\n",
    "\t\"lr\": [0.001],\n",
    "\t\"weight_decay\": [0.0],\n",
    "}\n",
    "gridsearch(\"RNNLSTM\", grid, X, y, folds=2, epochs=100)\n",
    "\n",
    "# grid = {\n",
    "# \t\"input_dim\": [5],\n",
    "# \t\"hidden_dim\": [128],\n",
    "# \t\"num_layers\": [4],\n",
    "# \t\"dropout\": [0.1],\n",
    "# \t\"lr\": [0.001],\n",
    "# \t\"weight_decay\": [0.0],\n",
    "# }\n",
    "# gridsearch(\"MLP\", grid, X, y)\n",
    "# gridpredict(\"MLP\", grid, query1)\n",
    "# gridpredict(\"MLP\", grid, query2)\n",
    "# gridpredict(\"MLP\", grid, query3)\n",
    "\n",
    "# INFERENCE PHASE\n",
    "def gridpredict(model_type, grid, query):\n",
    "\tquery = np.array(query, dtype=np.float32).reshape(1, -1)\n",
    "\tfor column in itertools.product(*grid.values()):\n",
    "\t\tmodel = instantiate(model_type, **dict(zip(grid.keys(), column))).to(DEVICE)\n",
    "\t\tscaler = joblib.load(os.path.join(SAVES_PATH, f\"{model.id}/scaler.pkl\"))\n",
    "\t\tquery = torch.tensor(scaler.transform(query), dtype=torch.float32).to(DEVICE)\n",
    "\t\tload(model)\n",
    "\n",
    "\t\tmodel.eval()\n",
    "\t\twith torch.no_grad(): probability = model(query).item()\n",
    "\t\tprint(f\"{model.id}: {probability:.9f}\")\n",
    "\n",
    "gridpredict(\"RNNLSTM\", grid, (1797531234, -15.5, -175.2, 600.0, 8.0))\n",
    "gridpredict(\"RNNLSTM\", grid, (1797531234, 1.0, 69.0, 300.0, 8.0))\n",
    "gridpredict(\"RNNLSTM\", grid, (1797531234, 20.0, 160.0, 500.0, 8.0))\n",
    "\n",
    "gridpredict(\"RNNLSTM\", grid, (1697531234, -15.5, -175.2, 600.0, 8.0))\n",
    "gridpredict(\"RNNLSTM\", grid, (1697531234, 1.0, 69.0, 300.0, 8.0))\n",
    "gridpredict(\"RNNLSTM\", grid, (1697531234, 20.0, 160.0, 500.0, 8.0))\n",
    "\n",
    "gridpredict(\"RNNLSTM\", grid, (1712345678, -15.5, -175.2, 600.0, 8.0))\n",
    "gridpredict(\"RNNLSTM\", grid, (1712345678, 1.0, 69.0, 300.0, 8.0))\n",
    "gridpredict(\"RNNLSTM\", grid, (1712345678, 20.0, 160.0, 500.0, 8.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
