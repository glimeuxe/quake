{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gregory\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from architectures import *\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import *\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 37\n",
    "ROOT_PATH = os.getcwd()\n",
    "os.makedirs(LOGS_PATH := os.path.join(ROOT_PATH, \"logs\"), exist_ok=True)\n",
    "os.makedirs(RAW_DATASET_PATH := os.path.join(ROOT_PATH, \"dataset\", \"raw\"), exist_ok=True)\n",
    "os.makedirs(PRODUCTION_DATASET_PATH := os.path.join(ROOT_PATH, \"dataset\", \"production\"), exist_ok=True)\n",
    "os.makedirs(MODELS_PATH := os.path.join(ROOT_PATH, \"models\"), exist_ok=True)\n",
    "\n",
    "SUBSAMPLE_SIZE = 10000\n",
    "NOISE_RATIO = 0.5\n",
    "EARTHQUAKE_RATIO = 0.5\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50\n",
    "PATIENCE = 7\n",
    "FINETUNING = False\n",
    "\n",
    "seed_functions(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "\t\"\"\"Computes, saves, and prints summary of preprocessed data.\"\"\"\n",
    "\n",
    "\t# Compute preprocessed data\n",
    "\tdata_processor = DataPreprocessing(\n",
    "\t\tsubsample_size=SUBSAMPLE_SIZE,\n",
    "\t\traw_dataset_path=RAW_DATASET_PATH,\n",
    "\t\tlogs_path=LOGS_PATH,\n",
    "\t\tnoise_ratio=NOISE_RATIO,\n",
    "\t\tearthquake_ratio=EARTHQUAKE_RATIO\n",
    "\t)\n",
    "\n",
    "\t# Save preprocessed data\n",
    "\tsignals = data_processor.subsample_traces\n",
    "\tnp.save(os.path.join(PRODUCTION_DATASET_PATH, f\"signals_{SUBSAMPLE_SIZE}.npy\"), np.array(list(signals.values())))\n",
    "\tmetadata = data_processor.subsample_metadata\n",
    "\tmetadata.to_feather(os.path.join(PRODUCTION_DATASET_PATH, f\"metadata_{SUBSAMPLE_SIZE}.feather\"))\n",
    "\twaveform_images = data_processor.create_waveform_images()\n",
    "\tnp.save(os.path.join(PRODUCTION_DATASET_PATH, f\"waveform_images_{SUBSAMPLE_SIZE}.npy\"), waveform_images)\n",
    "\tspectrogram_images = data_processor.create_spectrogram_images()\n",
    "\tnp.save(os.path.join(PRODUCTION_DATASET_PATH, f\"spectrogram_images_{SUBSAMPLE_SIZE}.npy\"), spectrogram_images)\n",
    "\n",
    "\t# Print summary of preprocessed data\n",
    "\tprint(f\"\"\"\n",
    "\t1. Expected samples: {SUBSAMPLE_SIZE}\n",
    "\t2. Actual samples: {len(signals)}\\n{metadata['category'].value_counts(normalize=True)}\n",
    "\t\"\"\")\n",
    "\n",
    "# preprocess_data()\n",
    "\n",
    "def visualise_data(num_samples=1):\n",
    "\t\"\"\"Randomly selects and plots pair(s) of waveform and spectrogram images.\"\"\"\n",
    "\n",
    "\t# Load saved images\n",
    "\twaveform_images = np.load(os.path.join(PRODUCTION_DATASET_PATH, f\"waveform_images_{SUBSAMPLE_SIZE}.npy\"))\n",
    "\tspectrogram_images = np.load(os.path.join(PRODUCTION_DATASET_PATH, f\"spectrogram_images_{SUBSAMPLE_SIZE}.npy\"))\n",
    "\n",
    "\t# Create figure with subplots\n",
    "\tfig, axes = plt.subplots(num_samples, 2, figsize=(6, 3 * num_samples))\n",
    "\n",
    "\t# Ensure axes is iterable for a single sample case\n",
    "\tif num_samples == 1: axes = [axes]\n",
    "\n",
    "\t# Plot random images\n",
    "\tfor i1, i2 in enumerate(np.random.choice(len(waveform_images), num_samples, replace=False)):\n",
    "\t\taxes[i1][0].imshow(waveform_images[i2])\n",
    "\t\taxes[i1][0].set_title(f\"Waveform {i2}\")\n",
    "\t\taxes[i1][0].axis(\"off\")\n",
    "\t\taxes[i1][1].imshow(spectrogram_images[i2])\n",
    "\t\taxes[i1][1].set_title(f\"Spectrogram {i2}\")\n",
    "\t\taxes[i1][1].axis(\"off\")\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "# visualise_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViTB16().to(DEVICE)\n",
    "\n",
    "# Load production dataset and compute labels\n",
    "spectrograms = np.load(os.path.join(PRODUCTION_DATASET_PATH, f\"spectrogram_images_{SUBSAMPLE_SIZE}.npy\"))\n",
    "metadata = pd.read_feather(os.path.join(PRODUCTION_DATASET_PATH, f\"metadata_{SUBSAMPLE_SIZE}.feather\"))\n",
    "labels = (metadata[\"category\"] == \"earthquake\").astype(np.float32).values  # 0 (noise), 1 (earthquake)\n",
    "\n",
    "# Normalize and convert spectrograms and labels to tensors\n",
    "spectrograms = torch.tensor(spectrograms.astype(np.float32) / 255.0).permute(0, 3, 1, 2)\n",
    "labels = torch.tensor(labels).view(-1, 1)\n",
    "\n",
    "def split_data(spectrograms, labels, test_size=0.2, dev_size=0.5):\n",
    "\ttrain_i, temp_i, train_labels, temp_labels = train_test_split(spectrograms, labels, test_size=test_size, stratify=labels, random_state=SEED)\n",
    "\tdev_i, test_i, dev_labels, test_labels = train_test_split(temp_i, temp_labels, test_size=dev_size, stratify=temp_labels, random_state=SEED)\n",
    "\treturn train_i, train_labels, dev_i, dev_labels, test_i, test_labels\n",
    "\n",
    "# Split production dataset into train, dev, and test sets\n",
    "train_i, train_labels, dev_i, dev_labels, test_i, test_labels = split_data(spectrograms, labels)\n",
    "\n",
    "def load_data(model):\n",
    "\ttrain_generator = torch.Generator()\n",
    "\ttrain_generator.manual_seed(SEED)\n",
    "\n",
    "\tif getattr(model, \"expects224\", False):\n",
    "\t\ttrain_loader = DataLoader(SpectrogramDataset224(SpectrogramDataset(train_i, train_labels)), batch_size=BATCH_SIZE, shuffle=True, generator=train_generator)\n",
    "\t\tdev_loader = DataLoader(SpectrogramDataset224(SpectrogramDataset(dev_i, dev_labels)), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\t\ttest_loader = DataLoader(SpectrogramDataset224(SpectrogramDataset(test_i, test_labels)), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\t\treturn train_loader, dev_loader, test_loader\n",
    "\n",
    "\ttrain_loader = DataLoader(SpectrogramDataset(train_i, train_labels), batch_size=BATCH_SIZE, shuffle=True, generator=train_generator)\n",
    "\tdev_loader = DataLoader(SpectrogramDataset(dev_i, dev_labels), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\ttest_loader = DataLoader(SpectrogramDataset(test_i, test_labels), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\treturn train_loader, dev_loader, test_loader\n",
    "\n",
    "train_loader, dev_loader, test_loader = load_data(model)\n",
    "\n",
    "if FINETUNING:\n",
    "\tpretrained_weights = torch.load(\"./models/R50ViTB16/best.pth\", map_location=DEVICE)\n",
    "\tmodel_dict = model.state_dict()\n",
    "\tcompatible_weights = {k: v for k, v in pretrained_weights.items() if k in model_dict and v.shape == model_dict[k].shape}\n",
    "\tmodel_dict.update(compatible_weights)\n",
    "\tmodel.load_state_dict(model_dict)\n",
    "\tprint(f\"Loaded {len(compatible_weights)} of {len(model_dict)} parameters from pretrained model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 of 50 - Training loss: 0.7548 - Validation loss: 0.6869\n",
      "Epoch: 2 of 50 - Training loss: 0.6498 - Validation loss: 0.6008\n",
      "Epoch: 3 of 50 - Training loss: 0.6052 - Validation loss: 0.4667\n",
      "Epoch: 4 of 50 - Training loss: 0.5036 - Validation loss: 0.4547\n",
      "Epoch: 5 of 50 - Training loss: 0.4365 - Validation loss: 0.3902\n",
      "Epoch: 6 of 50 - Training loss: 0.4596 - Validation loss: 0.5102\n",
      "Epoch: 7 of 50 - Training loss: 0.5723 - Validation loss: 0.5534\n",
      "Epoch: 8 of 50 - Training loss: 0.5280 - Validation loss: 0.4582\n",
      "Epoch: 9 of 50 - Training loss: 0.5127 - Validation loss: 0.5422\n",
      "Epoch: 10 of 50 - Training loss: 0.4991 - Validation loss: 0.4585\n",
      "Epoch: 11 of 50 - Training loss: 0.4620 - Validation loss: 0.3938\n",
      "Epoch: 12 of 50 - Training loss: 0.4022 - Validation loss: 0.3857\n",
      "Epoch: 13 of 50 - Training loss: 0.4099 - Validation loss: 0.4309\n",
      "Epoch: 14 of 50 - Training loss: 0.4100 - Validation loss: 0.3713\n",
      "Epoch: 15 of 50 - Training loss: 0.4260 - Validation loss: 0.4416\n",
      "Epoch: 16 of 50 - Training loss: 0.4004 - Validation loss: 0.3862\n",
      "Epoch: 17 of 50 - Training loss: 0.3952 - Validation loss: 0.3934\n",
      "Epoch: 18 of 50 - Training loss: 0.3931 - Validation loss: 0.3667\n",
      "Epoch: 19 of 50 - Training loss: 0.3876 - Validation loss: 0.3740\n",
      "Epoch: 20 of 50 - Training loss: 0.3977 - Validation loss: 0.3660\n",
      "Epoch: 21 of 50 - Training loss: 0.4345 - Validation loss: 0.6411\n",
      "Epoch: 22 of 50 - Training loss: 0.5831 - Validation loss: 0.5766\n",
      "Epoch: 23 of 50 - Training loss: 0.5715 - Validation loss: 0.5246\n",
      "Epoch: 24 of 50 - Training loss: 0.4675 - Validation loss: 0.3670\n",
      "Epoch: 25 of 50 - Training loss: 0.4718 - Validation loss: 0.3745\n",
      "Epoch: 26 of 50 - Training loss: 0.3788 - Validation loss: 0.4389\n",
      "Epoch: 27 of 50 - Training loss: 0.3711 - Validation loss: 0.3333\n",
      "Epoch: 28 of 50 - Training loss: 0.3756 - Validation loss: 0.3443\n",
      "Epoch: 29 of 50 - Training loss: 0.3711 - Validation loss: 0.3593\n",
      "Epoch: 30 of 50 - Training loss: 0.3703 - Validation loss: 0.3908\n",
      "Epoch: 31 of 50 - Training loss: 0.4536 - Validation loss: 0.3725\n",
      "Epoch: 32 of 50 - Training loss: 0.3684 - Validation loss: 0.3582\n",
      "Epoch: 33 of 50 - Training loss: 0.3561 - Validation loss: 0.3301\n",
      "Epoch: 34 of 50 - Training loss: 0.3646 - Validation loss: 0.3479\n",
      "Epoch: 35 of 50 - Training loss: 0.3889 - Validation loss: 0.3854\n",
      "Epoch: 36 of 50 - Training loss: 0.3866 - Validation loss: 0.3571\n",
      "Epoch: 37 of 50 - Training loss: 0.3717 - Validation loss: 0.3391\n",
      "Epoch: 38 of 50 - Training loss: 0.3675 - Validation loss: 0.3418\n",
      "Epoch: 39 of 50 - Training loss: 0.3550 - Validation loss: 0.3434\n",
      "Epoch: 40 of 50 - Training loss: 0.3499 - Validation loss: 0.3347\n",
      "Stopping early\n"
     ]
    }
   ],
   "source": [
    "# (1) In train_model, one may also compute metrics (e.g. F1) on the train or dev set. To save compute, we chose not to.\n",
    "\n",
    "def train_model(model, train_loader, dev_loader, criterion, optimizer):\n",
    "\t# Create model folder\n",
    "\tmodel_folder = os.path.join(MODELS_PATH, f\"{model.id}\")\n",
    "\tos.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "\tbest_dev_loss = float(\"inf\")\n",
    "\tbest_model_path = os.path.join(model_folder, \"best.pth\")\n",
    "\tpatience_counter = 0\n",
    "\ttrain_losses = []\n",
    "\tdev_losses = []\n",
    "\n",
    "\tfor epoch in range(NUM_EPOCHS):\n",
    "\t\t# Train model on train set\n",
    "\t\tmodel.train()\n",
    "\t\ttotal_loss = 0\n",
    "\t\tfor images, labels in train_loader:\n",
    "\t\t\timages, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\ttotal_loss += loss.item()\n",
    "\t\ttrain_loss = total_loss / len(train_loader)\n",
    "\t\ttrain_losses.append(train_loss)\n",
    "\n",
    "\t\t# Evaluate model on dev set\n",
    "\t\tmodel.eval()\n",
    "\t\tdev_loss = 0\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor images, labels in dev_loader:\n",
    "\t\t\t\timages, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\t\t\t\toutputs = model(images)\n",
    "\t\t\t\tdev_loss += criterion(outputs, labels).item()\n",
    "\t\tdev_loss /= len(dev_loader)\n",
    "\t\tdev_losses.append(dev_loss)\n",
    "\n",
    "\t\tprint(f\"Epoch: {epoch+1} of {NUM_EPOCHS} - Training loss: {train_loss:.4f} - Validation loss: {dev_loss:.4f}\")\n",
    "\n",
    "\t\t# Save model epoch checkpoint\n",
    "\t\ttorch.save(model.state_dict(), os.path.join(model_folder, f\"epoch={epoch+1}-dev_loss={dev_loss:.4f}.pth\"))\n",
    "\t\tif dev_loss < best_dev_loss:\n",
    "\t\t\tbest_dev_loss = dev_loss\n",
    "\t\t\ttorch.save(model.state_dict(), best_model_path)  # Save best model\n",
    "\t\t\tpatience_counter = 0  # Reset patience counter\n",
    "\t\telse:\n",
    "\t\t\tpatience_counter += 1\n",
    "\t\t\t# Stop early if needed\n",
    "\t\t\tif patience_counter >= PATIENCE:\n",
    "\t\t\t\tprint(\"Stopping early\")\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t# Save losses\n",
    "\tloss_data = {\"train_losses\": train_losses, \"dev_losses\": dev_losses}\n",
    "\twith open(os.path.join(model_folder, \"losses.json\"), \"w\") as f:\n",
    "\t\tjson.dump(loss_data, f)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "train_model(model, train_loader, dev_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_loss(model):\n",
    "\t# Load losses\n",
    "\tmodel_folder = os.path.join(MODELS_PATH, f\"{model.id}\")\n",
    "\twith open(os.path.join(model_folder, \"losses.json\"), \"r\") as f:\n",
    "\t\tloss_data = json.load(f)\n",
    "\ttrain_losses = loss_data[\"train_losses\"]\n",
    "\tdev_losses = loss_data[\"dev_losses\"]\n",
    "\n",
    "\tplt.figure(figsize=(8, 5))\n",
    "\tepochs = range(1, len(train_losses) + 1)\n",
    "\tplt.plot(epochs, train_losses, \"b-\", label=\"Training loss\")\n",
    "\tplt.plot(epochs, dev_losses, \"r-\", label=\"Validation loss\")\n",
    "\n",
    "\t# Annotate the best loss\n",
    "\tbest_epoch = np.argmin(dev_losses) + 1\n",
    "\tbest_loss = min(dev_losses)\n",
    "\tplt.plot(best_epoch, best_loss, \"ro\", markersize=8, label=f\"Best loss: {best_loss:.4f}\")\n",
    "\n",
    "\tplt.xlabel(\"Epoch\")\n",
    "\tplt.ylabel(\"Loss\")\n",
    "\tplt.legend()\n",
    "\tplt.gca().xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "def multivisualise_training_loss(models):\n",
    "\tplt.figure(figsize=(8, 5))\n",
    "\tfor model in models:\n",
    "\t\tmodel_folder = os.path.join(MODELS_PATH, f\"{model.id}\")\n",
    "\t\twith open(os.path.join(model_folder, \"losses.json\"), \"r\") as f:\n",
    "\t\t\tloss_data = json.load(f)\n",
    "\t\ttrain_losses = loss_data[\"train_losses\"]\n",
    "\t\tepochs = range(1, len(train_losses) + 1)\n",
    "\t\tplt.plot(epochs, train_losses, label=f\"{model.id} - train\")\n",
    "\tplt.xlabel(\"Epoch\")\n",
    "\tplt.ylabel(\"Training Loss\")\n",
    "\tplt.legend()\n",
    "\tplt.gca().xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "def multivisualise_validation_loss(models):\n",
    "\tplt.figure(figsize=(8, 5))\n",
    "\tfor model in models:\n",
    "\t\tmodel_folder = os.path.join(MODELS_PATH, f\"{model.id}\")\n",
    "\t\twith open(os.path.join(model_folder, \"losses.json\"), \"r\") as f:\n",
    "\t\t\tloss_data = json.load(f)\n",
    "\t\tdev_losses = loss_data[\"dev_losses\"]\n",
    "\t\tepochs = range(1, len(dev_losses) + 1)\n",
    "\t\tplt.plot(epochs, dev_losses, label=f\"{model.id} - val\")\n",
    "\tplt.xlabel(\"Epoch\")\n",
    "\tplt.ylabel(\"Validation Loss\")\n",
    "\tplt.legend()\n",
    "\tplt.gca().xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "\tmodel.eval()\n",
    "\tY_hat, Y = [], []\n",
    "\twith torch.no_grad():\n",
    "\t\tfor x, y in dataloader:\n",
    "\t\t\tY_hat.append(model(x.to(DEVICE)).round().cpu())\n",
    "\t\t\tY.append(y)\n",
    "\ttn, fp, fn, tp = confusion_matrix(torch.cat(Y), torch.cat(Y_hat)).ravel()\n",
    "\tf1 = compute_f1(tp, tn, fp, fn)\n",
    "\treturn {\n",
    "\t\t\"tp\": int(tp),\n",
    "\t\t\"tn\": int(tn),\n",
    "\t\t\"fp\": int(fp),\n",
    "\t\t\"fn\": int(fn),\n",
    "\t\t\"f1\": float(f1)\n",
    "\t}\n",
    "\n",
    "def load_weights(model):\n",
    "\tstate_dict = torch.load(os.path.join(MODELS_PATH, model.id, \"best.pth\"), weights_only=False)\n",
    "\tstate_dict.pop('_metadata', None)\n",
    "\tmodel.load_state_dict(state_dict)\n",
    "\n",
    "m = model.__class__().to(DEVICE)\n",
    "\n",
    "visualise_loss(m)\n",
    "\n",
    "load_weights(m)\n",
    "print(evaluate_model(m, test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
