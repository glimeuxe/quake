{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import DataPreprocessing, SpectrogramDataset, plot_waveform, plot_spectrogram\n",
    "\n",
    "ROOT_PATH = os.getcwd()\n",
    "\n",
    "RAW_DATASET_PATH = os.path.join(ROOT_PATH, \"dataset\", \"raw\")\n",
    "PRODUCTION_DATASET_PATH = os.path.join(ROOT_PATH, \"dataset\", \"production\")\n",
    "LOGS_PATH = os.path.join(ROOT_PATH, \"logs\")\n",
    "MODELS_PATH = os.path.join(ROOT_PATH, \"models\")\n",
    "\n",
    "SUBSAMPLE_SIZE = 10000\n",
    "NOISE_RATIO = 0.5\n",
    "EARTHQUAKE_RATIO = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "12.4\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "\t# Compute preprocessed data\n",
    "\tdata_processor = DataPreprocessing(\n",
    "\t\tsubsample_size=SUBSAMPLE_SIZE,\n",
    "\t\traw_dataset_path=RAW_DATASET_PATH,\n",
    "\t\tlogs_path=LOGS_PATH,\n",
    "\t\tnoise_ratio=NOISE_RATIO,\n",
    "\t\tearthquake_ratio=EARTHQUAKE_RATIO\n",
    "\t)\n",
    "\n",
    "\t# Save preprocessed data\n",
    "\tsignals = data_processor.subsample_traces\n",
    "\tnp.save(os.path.join(PRODUCTION_DATASET_PATH, f\"signals_{SUBSAMPLE_SIZE}.npy\"), np.array(list(signals.values())))\n",
    "\n",
    "\tmetadata = data_processor.subsample_metadata\n",
    "\tmetadata.to_feather(os.path.join(PRODUCTION_DATASET_PATH, f\"metadata_{SUBSAMPLE_SIZE}.feather\"))\n",
    "\n",
    "\twaveform_images = data_processor.create_waveform_images()\n",
    "\tnp.save(os.path.join(PRODUCTION_DATASET_PATH, f\"waveform_images_{SUBSAMPLE_SIZE}.npy\"), waveform_images)\n",
    "\n",
    "\tspectrogram_images = data_processor.create_spectrogram_images()\n",
    "\tnp.save(os.path.join(PRODUCTION_DATASET_PATH, f\"spectrogram_images_{SUBSAMPLE_SIZE}.npy\"), spectrogram_images)\n",
    "\n",
    "\t# Print summary of preprocessed data\n",
    "\tprint(f\"\"\"\n",
    "\t1. Expected samples: {SUBSAMPLE_SIZE}\n",
    "\t2. Actual samples: {len(signals)}\\n{metadata['category'].value_counts(normalize=True)}\n",
    "\t\"\"\")\n",
    "\n",
    "# preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_data(num_samples=1):\n",
    "\t\"\"\"Randomly selects and plots waveform and spectrogram images.\"\"\"\n",
    "\t# Load saved images\n",
    "\twaveform_images = np.load(os.path.join(PRODUCTION_DATASET_PATH, f\"waveform_images_{SUBSAMPLE_SIZE}.npy\"))\n",
    "\tspectrogram_images = np.load(os.path.join(PRODUCTION_DATASET_PATH, f\"spectrogram_images_{SUBSAMPLE_SIZE}.npy\"))\n",
    "\n",
    "\t# Create figure with subplots\n",
    "\tfig, axes = plt.subplots(num_samples, 2, figsize=(6, 3 * num_samples))\n",
    "\n",
    "\t# Ensure axes is iterable for a single sample case\n",
    "\tif num_samples == 1:\n",
    "\t\taxes = [axes]\n",
    "\n",
    "\t# Plot random images\n",
    "\tfor i1, i2 in enumerate(np.random.choice(len(waveform_images), num_samples, replace=False)):\n",
    "\t\taxes[i1][0].imshow(waveform_images[i2])\n",
    "\t\taxes[i1][0].set_title(f\"Waveform {i2}\")\n",
    "\t\taxes[i1][0].axis(\"off\")\n",
    "\t\taxes[i1][1].imshow(spectrogram_images[i2])\n",
    "\t\taxes[i1][1].set_title(f\"Spectrogram {i2}\")\n",
    "\t\taxes[i1][1].axis(\"off\")\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "visualise_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 37\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50\n",
    "PATIENCE = 7\n",
    "\n",
    "# Load production dataset and compute labels\n",
    "spectrograms = np.load(os.path.join(PRODUCTION_DATASET_PATH, f\"spectrogram_images_{SUBSAMPLE_SIZE}.npy\"))\n",
    "metadata = pd.read_feather(os.path.join(PRODUCTION_DATASET_PATH, f\"metadata_{SUBSAMPLE_SIZE}.feather\"))\n",
    "labels = (metadata[\"category\"] == \"earthquake\").astype(np.float32).values  # 0 (noise), 1 (earthquake)\n",
    "\n",
    "# Normalize and convert spectrograms and labels to tensors\n",
    "spectrograms = torch.tensor(spectrograms.astype(np.float32) / 255.0).permute(0, 3, 1, 2)\n",
    "labels = torch.tensor(labels).view(-1, 1)\n",
    "\n",
    "def split_data(spectrograms, labels, test_size=0.2, dev_size=0.5):\n",
    "\ttrain_i, temp_i, train_labels, temp_labels = train_test_split(spectrograms, labels, test_size=test_size, stratify=labels, random_state=SEED)\n",
    "\tdev_i, test_i, dev_labels, test_labels = train_test_split(temp_i, temp_labels, test_size=dev_size, stratify=temp_labels, random_state=SEED)\n",
    "\treturn train_i, train_labels, dev_i, dev_labels, test_i, test_labels\n",
    "\n",
    "# Split production dataset into train, dev, and test sets\n",
    "train_i, train_labels, dev_i, dev_labels, test_i, test_labels = split_data(spectrograms, labels)\n",
    "\n",
    "# Convert train, dev, and test sets to train, dev, and test loaders\n",
    "train_loader = DataLoader(SpectrogramDataset(train_i, train_labels), batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_loader = DataLoader(SpectrogramDataset(dev_i, dev_labels), batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(SpectrogramDataset(test_i, test_labels), batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "\n",
    "class SomnialUnit(nn.Module):\n",
    "\tdef __init__(self, in_channels, k=10):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.M = deque(maxlen=k)\n",
    "\t\tself.delta = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "\t\tself.beta = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(in_channels * 2, in_channels, kernel_size=3, padding=1), nn.Sigmoid()\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(self, x_t):\n",
    "\t\tself.M.append(x_t.detach())\n",
    "\t\tx_s = random.choice(self.M)\n",
    "\t\tif x_s.shape[0] != x_t.shape[0]:\n",
    "\t\t\tpad_size = x_t.shape[0] - x_s.shape[0]\n",
    "\t\t\tif pad_size > 0:\n",
    "\t\t\t\tx_s = torch.cat([x_s, torch.zeros((pad_size, *x_s.shape[1:]), device=x_t.device)], dim=0)\n",
    "\t\t\telse:\n",
    "\t\t\t\tx_s = x_s[:x_t.shape[0]]\n",
    "\t\tx_s_hat = self.delta(x_s)\n",
    "\t\tg = self.beta(torch.cat([x_t, x_s_hat], dim=1))\n",
    "\t\treturn g * x_s_hat + (1 - g) * x_t\n",
    "\n",
    "class SomnialCNN(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.id = \"SomnialCNN\"\n",
    "\t\tself.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "\t\tself.pool = nn.MaxPool2d(2, 2)\n",
    "\t\tself.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "\t\tself.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "\t\tself.su = SomnialUnit(in_channels=64)\n",
    "\t\tself.fc1 = nn.Linear(64 * 25 * 37, 128)\n",
    "\t\tself.fc2 = nn.Linear(128, 32)\n",
    "\t\tself.fc3 = nn.Linear(32, 16) ##\n",
    "\t\tself.fc4 = nn.Linear(16, 1)\n",
    "\t\tself.dropout = nn.Dropout(0.25)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.pool(F.relu(self.conv1(x)))\n",
    "\t\tx = self.pool(F.relu(self.conv2(x)))\n",
    "\t\tx = self.pool(F.relu(self.conv3(x)))\n",
    "\t\tx = self.su(x)\n",
    "\t\tx = torch.flatten(x, 1)\n",
    "\t\tx = F.relu(self.fc1(x))\n",
    "\t\tx = self.dropout(x)\n",
    "\t\tx = F.relu(self.fc2(x))\n",
    "\t\tx = self.dropout(x) ##\n",
    "\t\tx = F.relu(self.fc3(x))\n",
    "\t\tx = torch.sigmoid(self.fc4(x))\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, dev_loader, criterion, optimizer):\n",
    "\t# Create model folder\n",
    "\tmodel_folder = os.path.join(MODELS_PATH, f\"{model.id}\")\n",
    "\tos.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "\tbest_dev_loss = float(\"inf\")\n",
    "\tbest_model_path = os.path.join(model_folder, \"best.pth\")\n",
    "\tpatience_counter = 0\n",
    "\ttrain_losses = []\n",
    "\tdev_losses = []\n",
    "\n",
    "\tfor epoch in range(NUM_EPOCHS):\n",
    "\t\t# Train model on train set\n",
    "\t\tmodel.train()\n",
    "\t\ttotal_loss = 0\n",
    "\t\tfor images, labels in train_loader:\n",
    "\t\t\timages, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\ttotal_loss += loss.item()\n",
    "\t\ttrain_loss = total_loss / len(train_loader)\n",
    "\t\ttrain_losses.append(train_loss)\n",
    "\n",
    "\t\t# Evaluate model on dev set\n",
    "\t\tmodel.eval()\n",
    "\t\tdev_loss = 0\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor images, labels in dev_loader:\n",
    "\t\t\t\timages, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\t\t\t\toutputs = model(images)\n",
    "\t\t\t\tdev_loss += criterion(outputs, labels).item()\n",
    "\t\tdev_loss /= len(dev_loader)\n",
    "\t\tdev_losses.append(dev_loss)\n",
    "\n",
    "\t\tprint(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Train Loss: {train_loss:.4f} - Dev Loss: {dev_loss:.4f}\")\n",
    "\n",
    "\t\t# Save model epoch checkpoint\n",
    "\t\ttorch.save(model.state_dict(), os.path.join(model_folder, f\"epoch={epoch+1}-dev_loss={dev_loss:.4f}.pth\"))\n",
    "\n",
    "\t\tif dev_loss < best_dev_loss:\n",
    "\t\t\tbest_dev_loss = dev_loss\n",
    "\t\t\ttorch.save(model.state_dict(), best_model_path)  # Save best model\n",
    "\t\t\tpatience_counter = 0  # Reset patience counter\n",
    "\t\telse:\n",
    "\t\t\tpatience_counter += 1\n",
    "\t\t\t# Stop early if needed\n",
    "\t\t\tif patience_counter >= PATIENCE:\n",
    "\t\t\t\tprint(\"Stopping early\")\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t# Save losses\n",
    "\tloss_data = {\"train_losses\": train_losses, \"dev_losses\": dev_losses}\n",
    "\twith open(os.path.join(model_folder, \"losses.json\"), \"w\") as f:\n",
    "\t\tjson.dump(loss_data, f)\n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.2736 - Dev Loss: 0.1068\n",
      "Epoch 2/50 - Train Loss: 0.1345 - Dev Loss: 0.0695\n",
      "Epoch 3/50 - Train Loss: 0.0901 - Dev Loss: 0.0742\n",
      "Epoch 4/50 - Train Loss: 0.0738 - Dev Loss: 0.0588\n",
      "Epoch 5/50 - Train Loss: 0.0561 - Dev Loss: 0.0619\n",
      "Epoch 6/50 - Train Loss: 0.0585 - Dev Loss: 0.0544\n",
      "Epoch 7/50 - Train Loss: 0.0485 - Dev Loss: 0.0448\n",
      "Epoch 8/50 - Train Loss: 0.0449 - Dev Loss: 0.0475\n",
      "Epoch 9/50 - Train Loss: 0.0454 - Dev Loss: 0.0486\n",
      "Epoch 10/50 - Train Loss: 0.0367 - Dev Loss: 0.0368\n",
      "Epoch 11/50 - Train Loss: 0.0486 - Dev Loss: 0.0727\n",
      "Epoch 12/50 - Train Loss: 0.0369 - Dev Loss: 0.0411\n",
      "Epoch 13/50 - Train Loss: 0.0263 - Dev Loss: 0.0411\n",
      "Epoch 14/50 - Train Loss: 0.0307 - Dev Loss: 0.0917\n",
      "Epoch 15/50 - Train Loss: 0.0253 - Dev Loss: 0.0400\n",
      "Epoch 16/50 - Train Loss: 0.0163 - Dev Loss: 0.0447\n",
      "Epoch 17/50 - Train Loss: 0.0236 - Dev Loss: 0.0403\n",
      "Stopping early\n"
     ]
    }
   ],
   "source": [
    "model = SomnialCNN().to(DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_model(model, train_loader, dev_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics: {'accuracy': 0.98500, 'precision': 0.99189, 'TPR': 0.97800, 'FPR': 0.00800}\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "\ty_true, y_pred = y_true.cpu().numpy(), (y_pred.cpu().numpy() > 0.5)\n",
    "\tacc = accuracy_score(y_true, y_pred)\n",
    "\tprecision = precision_score(y_true, y_pred, zero_division=0)\n",
    "\trecall = recall_score(y_true, y_pred)\n",
    "\ttn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\ttpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\tfpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\treturn {\n",
    "\t\t\"accuracy\": round(acc, 5),\n",
    "\t\t\"precision\": round(precision, 5),\n",
    "\t\t\"TPR\": float(round(tpr, 5)),\n",
    "\t\t\"FPR\": float(round(fpr, 5))\n",
    "\t}\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "\tmodel.eval()\n",
    "\ty_true, y_pred = [], []\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tfor images, labels in test_loader:\n",
    "\t\t\timages, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\ty_true.append(labels)\n",
    "\t\t\ty_pred.append(outputs)\n",
    "\n",
    "\ty_true = torch.cat(y_true, dim=0)\n",
    "\ty_pred = torch.cat(y_pred, dim=0)\n",
    "\tmetrics = compute_metrics(y_true, y_pred)\n",
    "\tprint(f\"Test Metrics: {{'accuracy': {metrics['accuracy']:.5f}, \"\n",
    "\t\tf\"'precision': {metrics['precision']:.5f}, \"\n",
    "\t\tf\"'TPR': {metrics['TPR']:.5f}, \"\n",
    "\t\tf\"'FPR': {metrics['FPR']:.5f}}}\")\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(MODELS_PATH, f\"{model.id}\", \"best.pth\")))\n",
    "evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
