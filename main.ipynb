{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "12.4\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import DataPreprocessing, SpectrogramDataset, plot_waveform, plot_spectrogram\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "ROOT_PATH = os.getcwd()\n",
    "LOGS_PATH = os.path.join(ROOT_PATH, \"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Preprocessing}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATASET_PATH = os.path.join(ROOT_PATH, \"dataset\", \"raw\")\n",
    "PRODUCTION_DATASET_PATH = os.path.join(ROOT_PATH, \"dataset\", \"production\")\n",
    "\n",
    "SUBSAMPLE_SIZE = 10000\n",
    "NOISE_RATIO = 0.5\n",
    "EARTHQUAKE_RATIO = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "\t\"\"\"Computes, saves, and prints summary of preprocessed data.\"\"\"\n",
    "\n",
    "\t# Compute preprocessed data\n",
    "\tdata_processor = DataPreprocessing(\n",
    "\t\tsubsample_size=SUBSAMPLE_SIZE,\n",
    "\t\traw_dataset_path=RAW_DATASET_PATH,\n",
    "\t\tlogs_path=LOGS_PATH,\n",
    "\t\tnoise_ratio=NOISE_RATIO,\n",
    "\t\tearthquake_ratio=EARTHQUAKE_RATIO\n",
    "\t)\n",
    "\n",
    "\t# Save preprocessed data\n",
    "\tsignals = data_processor.subsample_traces\n",
    "\tnp.save(os.path.join(PRODUCTION_DATASET_PATH, f\"signals_{SUBSAMPLE_SIZE}.npy\"), np.array(list(signals.values())))\n",
    "\tmetadata = data_processor.subsample_metadata\n",
    "\tmetadata.to_feather(os.path.join(PRODUCTION_DATASET_PATH, f\"metadata_{SUBSAMPLE_SIZE}.feather\"))\n",
    "\twaveform_images = data_processor.create_waveform_images()\n",
    "\tnp.save(os.path.join(PRODUCTION_DATASET_PATH, f\"waveform_images_{SUBSAMPLE_SIZE}.npy\"), waveform_images)\n",
    "\tspectrogram_images = data_processor.create_spectrogram_images()\n",
    "\tnp.save(os.path.join(PRODUCTION_DATASET_PATH, f\"spectrogram_images_{SUBSAMPLE_SIZE}.npy\"), spectrogram_images)\n",
    "\n",
    "\t# Print summary of preprocessed data\n",
    "\tprint(f\"\"\"\n",
    "\t1. Expected samples: {SUBSAMPLE_SIZE}\n",
    "\t2. Actual samples: {len(signals)}\\n{metadata['category'].value_counts(normalize=True)}\n",
    "\t\"\"\")\n",
    "\n",
    "# preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_data(num_samples=1):\n",
    "\t\"\"\"Randomly selects a pair of waveform and spectrogram images to plot.\"\"\"\n",
    "\n",
    "\t# Load saved images\n",
    "\twaveform_images = np.load(os.path.join(PRODUCTION_DATASET_PATH, f\"waveform_images_{SUBSAMPLE_SIZE}.npy\"))\n",
    "\tspectrogram_images = np.load(os.path.join(PRODUCTION_DATASET_PATH, f\"spectrogram_images_{SUBSAMPLE_SIZE}.npy\"))\n",
    "\n",
    "\t# Create figure with subplots\n",
    "\tfig, axes = plt.subplots(num_samples, 2, figsize=(6, 3 * num_samples))\n",
    "\n",
    "\t# Ensure axes is iterable for a single sample case\n",
    "\tif num_samples == 1:\n",
    "\t\taxes = [axes]\n",
    "\n",
    "\t# Plot random images\n",
    "\tfor i1, i2 in enumerate(np.random.choice(len(waveform_images), num_samples, replace=False)):\n",
    "\t\taxes[i1][0].imshow(waveform_images[i2])\n",
    "\t\taxes[i1][0].set_title(f\"Waveform {i2}\")\n",
    "\t\taxes[i1][0].axis(\"off\")\n",
    "\t\taxes[i1][1].imshow(spectrogram_images[i2])\n",
    "\t\taxes[i1][1].set_title(f\"Spectrogram {i2}\")\n",
    "\t\taxes[i1][1].axis(\"off\")\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "visualise_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Training}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = os.path.join(ROOT_PATH, \"models\")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 37\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50\n",
    "PATIENCE = 7\n",
    "\n",
    "# Load production dataset and compute labels\n",
    "spectrograms = np.load(os.path.join(PRODUCTION_DATASET_PATH, f\"spectrogram_images_{SUBSAMPLE_SIZE}.npy\"))\n",
    "metadata = pd.read_feather(os.path.join(PRODUCTION_DATASET_PATH, f\"metadata_{SUBSAMPLE_SIZE}.feather\"))\n",
    "labels = (metadata[\"category\"] == \"earthquake\").astype(np.float32).values  # 0 (noise), 1 (earthquake)\n",
    "\n",
    "# Normalize and convert spectrograms and labels to tensors\n",
    "spectrograms = torch.tensor(spectrograms.astype(np.float32) / 255.0).permute(0, 3, 1, 2)\n",
    "labels = torch.tensor(labels).view(-1, 1)\n",
    "\n",
    "def split_data(spectrograms, labels, test_size=0.2, dev_size=0.5):\n",
    "\ttrain_i, temp_i, train_labels, temp_labels = train_test_split(spectrograms, labels, test_size=test_size, stratify=labels, random_state=SEED)\n",
    "\tdev_i, test_i, dev_labels, test_labels = train_test_split(temp_i, temp_labels, test_size=dev_size, stratify=temp_labels, random_state=SEED)\n",
    "\treturn train_i, train_labels, dev_i, dev_labels, test_i, test_labels\n",
    "\n",
    "# Split production dataset into train, dev, and test sets\n",
    "train_i, train_labels, dev_i, dev_labels, test_i, test_labels = split_data(spectrograms, labels)\n",
    "\n",
    "# Convert train, dev, and test sets to train, dev, and test loaders\n",
    "train_loader = DataLoader(SpectrogramDataset(train_i, train_labels), batch_size=BATCH_SIZE, shuffle=True)\n",
    "dev_loader = DataLoader(SpectrogramDataset(dev_i, dev_labels), batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(SpectrogramDataset(test_i, test_labels), batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectures import CNN1, CNN2, SCNN1, SCNN2\n",
    "\n",
    "def train_model(model, train_loader, dev_loader, criterion, optimizer):\n",
    "\t# Create model folder\n",
    "\tmodel_folder = os.path.join(MODELS_PATH, f\"{model.id}\")\n",
    "\tos.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "\tbest_dev_loss = float(\"inf\")\n",
    "\tbest_model_path = os.path.join(model_folder, \"best.pth\")\n",
    "\tpatience_counter = 0\n",
    "\ttrain_losses = []\n",
    "\tdev_losses = []\n",
    "\n",
    "\tfor epoch in range(NUM_EPOCHS):\n",
    "\t\t# Train model on train set\n",
    "\t\tmodel.train()\n",
    "\t\ttotal_loss = 0\n",
    "\t\tfor images, labels in train_loader:\n",
    "\t\t\timages, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\ttotal_loss += loss.item()\n",
    "\t\ttrain_loss = total_loss / len(train_loader)\n",
    "\t\ttrain_losses.append(train_loss)\n",
    "\n",
    "\t\t# Evaluate model on dev set\n",
    "\t\tmodel.eval()\n",
    "\t\tdev_loss = 0\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor images, labels in dev_loader:\n",
    "\t\t\t\timages, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\t\t\t\toutputs = model(images)\n",
    "\t\t\t\tdev_loss += criterion(outputs, labels).item()\n",
    "\t\tdev_loss /= len(dev_loader)\n",
    "\t\tdev_losses.append(dev_loss)\n",
    "\n",
    "\t\tprint(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Train Loss: {train_loss:.4f} - Dev Loss: {dev_loss:.4f}\")\n",
    "\n",
    "\t\t# Save model epoch checkpoint\n",
    "\t\ttorch.save(model.state_dict(), os.path.join(model_folder, f\"epoch={epoch+1}-dev_loss={dev_loss:.4f}.pth\"))\n",
    "\n",
    "\t\tif dev_loss < best_dev_loss:\n",
    "\t\t\tbest_dev_loss = dev_loss\n",
    "\t\t\ttorch.save(model.state_dict(), best_model_path)  # Save best model\n",
    "\t\t\tpatience_counter = 0  # Reset patience counter\n",
    "\t\telse:\n",
    "\t\t\tpatience_counter += 1\n",
    "\t\t\t# Stop early if needed\n",
    "\t\t\tif patience_counter >= PATIENCE:\n",
    "\t\t\t\tprint(\"Stopping early\")\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t# Save losses\n",
    "\tloss_data = {\"train_losses\": train_losses, \"dev_losses\": dev_losses}\n",
    "\twith open(os.path.join(model_folder, \"losses.json\"), \"w\") as f:\n",
    "\t\tjson.dump(loss_data, f)\n",
    "\n",
    "model = CNN(training=True).to(DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_model(model, train_loader, dev_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualise_training(model):\n",
    "\tmodel_folder = os.path.join(MODELS_PATH, f\"{model.id}\")\n",
    "\twith open(os.path.join(model_folder, \"losses.json\"), \"r\") as f:\n",
    "\t\tloss_data = json.load(f)\n",
    "\ttrain_losses = loss_data[\"train_losses\"]\n",
    "\tdev_losses = loss_data[\"dev_losses\"]\n",
    "\tplt.figure(figsize=(8, 5))\n",
    "\tepochs = range(1, len(train_losses) + 1)\n",
    "\tplt.plot(epochs, train_losses, 'b-', label='Training loss')\n",
    "\tplt.plot(epochs, dev_losses, 'r-', label='Validation loss')\n",
    "\tplt.xlabel(\"Epoch\")\n",
    "\tplt.ylabel(\"Loss\")\n",
    "\tplt.legend()\n",
    "\tbest_epoch = np.argmin(dev_losses) + 1\n",
    "\tbest_loss = min(dev_losses)\n",
    "\tplt.plot(best_epoch, best_loss, 'ro', markersize=8)\n",
    "\tplt.annotate(\n",
    "\t\tf'Best: {best_loss:.4f}',\n",
    "\t\txy=(best_epoch, best_loss),\n",
    "\t\txytext=(best_epoch + 0.5, best_loss + 0.1),\n",
    "\t\tarrowprops=dict(facecolor='black', shrink=0.05, width=1.5)\n",
    "\t)\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\n",
    "visualise_training(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Inference}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODELS_PATH = os.path.join(ROOT_PATH, \"trained_models\")\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "\ty_true, y_pred = y_true.cpu().numpy(), (y_pred.cpu().numpy() > 0.5)\n",
    "\tacc = accuracy_score(y_true, y_pred)\n",
    "\tprecision = precision_score(y_true, y_pred, zero_division=0)\n",
    "\trecall = recall_score(y_true, y_pred)\n",
    "\ttn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\ttpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\tfpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "\treturn {\n",
    "\t\t\"accuracy\": round(acc, 5),\n",
    "\t\t\"precision\": round(precision, 5),\n",
    "\t\t\"TPR\": float(round(tpr, 5)),\n",
    "\t\t\"FPR\": float(round(fpr, 5))\n",
    "\t}\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "\tmodel.eval()\n",
    "\ty_true, y_pred = [], []\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tfor images, labels in test_loader:\n",
    "\t\t\timages, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\ty_true.append(labels)\n",
    "\t\t\ty_pred.append(outputs)\n",
    "\n",
    "\ty_true = torch.cat(y_true, dim=0)\n",
    "\ty_pred = torch.cat(y_pred, dim=0)\n",
    "\tmetrics = compute_metrics(y_true, y_pred)\n",
    "\tprint(f\"Test Metrics: {{'accuracy': {metrics['accuracy']:.5f}, \"\n",
    "\t\tf\"'precision': {metrics['precision']:.5f}, \"\n",
    "\t\tf\"'TPR': {metrics['TPR']:.5f}, \"\n",
    "\t\tf\"'FPR': {metrics['FPR']:.5f}}}\")\n",
    "\n",
    "model = CNN(training=False).to(DEVICE)\n",
    "model.load_state_dict(torch.load(os.path.join(MODELS_PATH, f\"SCNNv2\", \"best.pth\")))\n",
    "evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
